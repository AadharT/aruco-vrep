{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to remote API server\n",
      "Versão OpenCV:  3.4.2\n",
      "Versão Python:  3.6.5\n",
      "Nothing detected!\n",
      "Nothing detected!\n",
      "Nothing detected!\n",
      "Program ended\n"
     ]
    }
   ],
   "source": [
    "# print('Program started')\n",
    "import vrep\n",
    "import numpy as np\n",
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import sys, time, math\n",
    "from platform import python_version\n",
    "\n",
    "##############Comunicação com V-REP##########################\n",
    "serverIP = '127.0.0.1';\n",
    "serverPort = 19999; #Esta porta do servidor está sempre aberta\n",
    "vrep.simxFinish(-1);\n",
    "clientID=vrep.simxStart(serverIP,serverPort,True,True,5000,5);\n",
    "#############################################################\n",
    "\n",
    "windowName = \"Imagem-Processada\" #Name of the window created\n",
    "cv2.namedWindow(windowName, cv2.WINDOW_NORMAL)#Setting the name ande type of window\n",
    "cv2.setWindowProperty(windowName, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FREERATIO)#setting fullscreen\n",
    "\n",
    "#-- Define Tag\n",
    "id_to_find = 2\n",
    "marker_size = 100 #-cm\n",
    "\n",
    "#-- Get the camera calibration\n",
    "calib_path = ''\n",
    "camera_matrix = np.loadtxt(calib_path+'cameraMatrix.txt', delimiter = ',')\n",
    "camera_distortion = np.loadtxt(calib_path+'cameraDistortion.txt', delimiter = ',')\n",
    "\n",
    "#-- 180 deg rotation matrix around x axis\n",
    "R_flip = np.zeros((3,3), dtype=np.float)\n",
    "R_flip[0,0] = 1.0\n",
    "R_flip[1,1] = -1.0\n",
    "R_flip[2,2] = -1.0\n",
    "\n",
    "ret = np.zeros((3,3), dtype=np.float)\n",
    "\n",
    "#-- Define the Aruco dictionary\n",
    "aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_50)\n",
    "parameters =  aruco.DetectorParameters_create()\n",
    "\n",
    "if clientID!=-1:\n",
    "    print ('Connected to remote API server')\n",
    "    print ('Versão OpenCV: ',cv2.__version__)\n",
    "    print ('Versão Python: ',python_version())\n",
    "    \n",
    "    err,visionHandle = vrep.simxGetObjectHandle(clientID,'Vision_sensor',vrep.simx_opmode_oneshot_wait)\n",
    "    \n",
    "    while err == 0:\n",
    "        \n",
    "        err,visionHandle = vrep.simxGetObjectHandle(clientID,'Vision_sensor',vrep.simx_opmode_oneshot_wait)\n",
    "        err,res,imgList = vrep.simxGetVisionSensorImage(clientID,visionHandle,0,vrep.simx_opmode_oneshot_wait) #Imagens do sensor\n",
    "        \n",
    "        img = (np.array(imgList))[::-1]#Passa de lista para uma array e inverte a array para plotar corretamente\n",
    "        imgRGB = cv2.flip(np.uint8(img.reshape(720,1280,3)),1) #Transforma em uma imagem RGB e espelha\n",
    "        \n",
    "        #-- Convert in gray scale\n",
    "        gray = cv2.cvtColor(imgRGB, cv2.COLOR_BGR2GRAY) #-- remember, OpenCV stores color images in Blue, Green, Red\n",
    "        \n",
    "        #-- Find all the aruco markers in the image\n",
    "        corners, ids, rejected = aruco.detectMarkers(image=gray, \n",
    "                                                     dictionary=aruco_dict, \n",
    "                                                     parameters=parameters,\n",
    "                                                     cameraMatrix=camera_matrix, \n",
    "                                                     distCoeff=camera_distortion)\n",
    "        \n",
    "        if ids != None and ids[0] == id_to_find:\n",
    "        \n",
    "            #-- ret= [rvec,tvec, ?]\n",
    "            #-- array of rotation and position of each marker in camera frame\n",
    "            #-- rvec = [[rvec_1, [rvec2], ...]]  attitude of the marker respect to camera frame\n",
    "            #-- tvec = [[tvec_1, [tvec2], ...]]  position of the marker in camera frame\n",
    "            ret = aruco.estimatePoseSingleMarkers(corners, marker_size, camera_matrix, camera_distortion)\n",
    "\n",
    "            #-- Unpack the output, get only the first\n",
    "            rvec, tvec = ret[0][0,0,:], ret[1][0,0,:]\n",
    "\n",
    "            #-- Draw the detected marker and put a reference frame over it\n",
    "            aruco.drawDetectedMarkers(imgRGB, corners)\n",
    "            aruco.drawAxis(imgRGB, camera_matrix, camera_distortion, rvec, tvec, 40)\n",
    "\n",
    "            #Display the resulting frame\n",
    "            cv2.imshow(windowName,imgRGB)\n",
    "\n",
    "            if cv2.waitKey(1) == 27: # exit on ESC\n",
    "                break\n",
    "        \n",
    "        else:\n",
    "            print(\"Nothing detected!\")\n",
    "            #Display the resulting frame\n",
    "            cv2.imshow(windowName,imgRGB)          \n",
    "            if cv2.waitKey(1) == 27: # exit on ESC\n",
    "                break\n",
    "\n",
    "    # Now close the connection to V-REP:\n",
    "    vrep.simxFinish(clientID)\n",
    "\n",
    "else:\n",
    "    print ('Failed connecting to remote API server')\n",
    "print ('Program ended')\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
